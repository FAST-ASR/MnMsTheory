\documentclass[class=article, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}
\usepackage{subcaption}
\usepackage{../mltheory}
\usepackage{amsfonts}

\begin{document}

\subsection{Definition}

A (discrete-time) Markov chain is a stochastic process for which the
joint distribution of $N$ consecutive samples
$\Matrix{z} = (z_1, \dots, z_N)^\top$ factorizes as:
\begin{align}
    p(\Matrix{z}) &= p(z_1)\prod_{n=2}^N p(z_n | z_{n-1}),
\end{align}

\subsection{Graphical and Matrix Representation}

When $z_n$ is discrete, i.e $z_n \in \mathcal{S}$ and
$| \mathcal{S} | \le \aleph_0$ \footnote{
    This notation is a little bit
    pedantic but necessary in order to include Markov chains with
    countably infinite states (as defined in the Dirichlet-process HMM
    for instance).
}, the transition probabilities $p(z_n|z_{n-1})$ of the Markov chain is
often represented as a graph or a matrix.

For instance, if we have $z_n \in \{a, b, c\}$, the \emph{transition matrix}
is given by:
\begin{align}
    \Matrix{T} &= \begin{bmatrix}
        p(z_n = a | z_{n-1} = a)  & p(z_n = b | z_{n-1} = a) & p(z_n = c | z_{n-1} = a) \\
        p(z_n = a | z_{n-1} = b)  & p(z_n = b | z_{n-1} = a) & p(z_n = c | z_{n-1} = b) \\
        p(z_n = a | z_{n-1} = c)  & p(z_n = b | z_{n-1} = c) & p(z_n = c | z_{n-1} = c) \\
    \end{bmatrix},
\end{align}
and the corresponding graph representation is given in Fig. \ref{markovchains:fig:graph}.

\begin{figure}[t]
    \centering
    \import{./}{figures/graph}
    \caption{Graphical representation of a Markov chain. $t_{ij}$ is the
     element of $\Matrix{T}$ at the $i$th row and $j$th column.}
    \label{markovchains:fig:graph}
\end{figure}
%

Whereas the graph conveniently represents the possible trajectories in
the state-space, the transition matrix $\Matrix{T}$ allows to express
state marginalization as a matrix-vector multiplication. For instance:
\begin{align}
    p(z_n) &= \sum_{i \in \{a, b, c\} } p(z_{n-1}=i, z_n) \\
    &= \sum_{i \in \{a, b, c\}} p(z_n | z_{n-1} = i) p(z_{n-1} = i) \\
    \Matrix{v}_n &= \Matrix{T} \Matrix{v}_{n-1} \label{markovchains:eq:smarginal}
\end{align},
where:
\begin{align}
    \Matrix{v}_n &= \begin{bmatrix}
        p(z_n = a) \\
        p(z_n = b) \\
        p(z_n = c)
\end{bmatrix}.
\end{align}

Equation \eqref{markovchains:eq:smarginal} is the ``core'' operation of many
Markov chains related algorithm such as forward-backward (for training models)
and viterbi (for decoding speech). For Markov chains that have a large number
of states, this operation is problematic as its complexity is quadratic in the
number of states: $\mathcal{O}(2D^2)$ where $D$ is the number of states.
The rest of the document describes how to exploit the structure of the Markov
chains to decrease the complexity of this operation.

\subsection{Compact graphical form}
In many application, the transition probabilities have some structure
allowing to represent the Markov chain in a more compact manner. For
instance, let's consider the following transition probabilities:
\begin{align}
    p(z_n = j | z_{n-1} = i) &= \begin{cases}
        \gamma + \nu_i \delta_j & \text{if } i = a \text{ and } j=b \\
        \nu_i\delta_j & \text{otherwise}.
    \end{cases}
\end{align}
Defined in this way, this Markov chain has $2 \cdot 3 + 1 = 7$
parameters instead of $3 \cdot 3 = 9$ in the general case. The graphical
representation of this constrained Markov chain is shown in
Fig.~\ref{markovchains:fig:consgraph}.
%
\begin{figure}[t]
    \centering
    \import{./}{figures/consgraph}
    \caption{Graphical representation of a constrained Markov chain.
    The filled node is a ``phony'' state equivalent of the
    \emph{epsilon-arc} in the WFST framework.}
    \label{markovchains:fig:consgraph}
\end{figure}

\subsection{Efficient marginalization}

In many applications, we would like to use the structure of the Markov
chain to efficiently marginalize over a state. The formula in
\eqref{markovchains:eq:smarginal} can be prohibitive to evaluate if the
state-space is large. The idea is to use the constraints of the Markov
chain to efficiently calculate the matrix-vector product.


In our particular example, observe that the transition matrix can be
written as:
\begin{align}
    \Matrix{T} &= \Matrix{S} + \Matrix{\nu} \Matrix{\delta}^\top,
\end{align}
where:
\begin{align}
    \Matrix{S} &= \begin{bmatrix}
        0 & \gamma & 0 \\
        0 & 0 & 0 \\
        0 & 0 & 0
    \end{bmatrix} \;
    \Matrix{\nu} = \begin{bmatrix} \nu_a \\ \nu_b \\ \nu_c \end{bmatrix}\;
    \Matrix{\delta} = \begin{bmatrix} \delta_a \\ \delta_b \\ \delta_c \end{bmatrix}.
\end{align}
Consequently, we have:
\begin{align}
    \Matrix{T} \Matrix{v}_{n-1} &= (\Matrix{S} +
        \Matrix{\nu} \Matrix{\delta}^\top) \Matrix{v}_{n-1},
\end{align}
and using the associativity and the distributive properties of the addition and
multiplication we re-write it as:
\begin{align}
    \Matrix{T} \Matrix{v}_{n-1} &= \Matrix{S} \Matrix{v}_{n-1} +
        \Matrix{\nu} (\Matrix{\delta}^\top \Matrix{v}_{n-1}) \label{markovchains:eq:fast_smarginal}.
\end{align}
Calculating the matrix-vector product following the operation order of
\eqref{markovchains:eq:fast_smarginal}, the complexity reduces to:
$\mathcal{O}(2Q + 2D)$ where $Q$ is the number of non-zero elements in
$\mathbf{S}$.

\paragraph{Remark:} in the general case, it is easy to show that:
\begin{align}
    \Matrix{T} &= \Matrix{S} + \sum_{k}^K \Matrix{\nu}_k \Matrix{\delta}_k^\top,
    \label{markovchains:eq:tfactor}
\end{align}
where $K$ is the number of ``phony'' states in the graphical representation
of the Markov chain\footnote{
    Here, I assume that there is no looping path starting from a ``phony''
    state that does not contain a ``real'' state. This constraint
    is necessarly met in practice.
}\footnote{
    The factorization in \eqref{markovchains:eq:tfactor} is not unique.
}.

\end{document}

